{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d348f9c-3080-4eff-a28d-213833a46b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle as pickle\n",
    "from pydoc import locate\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "import data_loaders.data_loader as dataloader\n",
    "from data_loaders.data_loader import MyDataCollatorWithPadding\n",
    "import utils.util as utils\n",
    "from omegaconf import OmegaConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bc58c6f3-c54b-412f-9a63-88b849ac71c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = OmegaConf.load(f\"./config/base_config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "62068445-684b-4dce-af87-910c2d5366fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at klue/roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\n"
     ]
    }
   ],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_name = conf.model.model_name\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "data_collator = MyDataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3)\n",
    "\n",
    "model.parameters\n",
    "model.to(device)\n",
    "model.eval()\n",
    "print(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b026a128-97cc-47df-9080-deed6a46e1f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897c159cb8694dfdb7d755ccf3958079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizing:   0%|          | 0/4846 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Tokenized data keys ==========\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n",
      "        labels                                           sentence  \\\n",
      "0      neutral  According to Gran, the company has no plans to...   \n",
      "1      neutral  Technopolis plans to develop in stages an area...   \n",
      "2     negative  The international electronic industry company ...   \n",
      "3     positive  With the new production plant the company woul...   \n",
      "4     positive  According to the company's updated strategy fo...   \n",
      "...        ...                                                ...   \n",
      "4841  negative  LONDON MarketWatch -- Share prices ended lower...   \n",
      "4842   neutral  Rinkuskiai's beer sales fell by 6.5 per cent t...   \n",
      "4843  negative  Operating profit fell to EUR 35.4 mn from EUR ...   \n",
      "4844  negative  Net sales of the Paper segment decreased to EU...   \n",
      "4845  negative  Sales in Finland decreased by 10.5 % in Januar...   \n",
      "\n",
      "                                           kor_sentence  \n",
      "0     Gran에 따르면, 그 회사는 회사가 성장하고 있는 곳이지만, 모든 생산을 러시아로...  \n",
      "1     테크노폴리스는 컴퓨터 기술과 통신 분야에서 일하는 회사들을 유치하기 위해 10만 평...  \n",
      "2     국제 전자산업 회사인 엘코텍은 탈린 공장에서 수십 명의 직원을 해고했으며, 이전의 ...  \n",
      "3     새로운 생산공장으로 인해 회사는 예상되는 수요 증가를 충족시킬 수 있는 능력을 증가...  \n",
      "4     2009-2012년 회사의 업데이트된 전략에 따르면, Basware는 20% - 4...  \n",
      "...                                                 ...  \n",
      "4841  런던 마켓워치 -- 은행주의 반등이 FTSE 100지수의 약세를 상쇄하지 못하면서 ...  \n",
      "4842  린쿠스키아의 맥주 판매량은 416만 리터로 6.5% 감소했으며 카우노 알루스의 맥주...  \n",
      "4843  영업이익은 2007년 68.8 mn에서 35.4 mn으로 떨어졌으며, 선박 판매 이...  \n",
      "4844  페이퍼 부문 순매출은 2008년 2분기 241.1 mn에서 2009년 2분기 221...  \n",
      "4845   핀란드에서의 판매는 1월에 10.5% 감소한 반면, 국외에서의 판매는 17% 감소했다.  \n",
      "\n",
      "[4846 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b52ec3222ba3419bad60442b910bb64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizing:   0%|          | 0/4846 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Tokenized data keys ==========\n",
      "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    0, 15895, 17664,  2008,  2039,  4586,  7052, 15053,  3947,    16,\n",
       "          5062, 20793, 22058, 13866,  2041, 19665, 16434, 16654,  7052,    80,\n",
       "         15176, 21058, 31138,  4596,  7052,    54, 23559,  7856,    16, 13532,\n",
       "          7088, 24899, 16845, 11376, 14092, 16387,  5062, 20793, 22058, 11376,\n",
       "         23246,  5936,  4586,    18,     2]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'labels': tensor(0)}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## load predict datset\n",
    "RE_predict_dataset = dataloader.load_predict_dataset(tokenizer, conf.path.predict_path, conf)\n",
    "RE_test_dataset = dataloader.load_dataset(tokenizer, conf.path.test_path, conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d3cb2585-2d57-496d-8675-956a4bde0205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([    0, 15895, 17664,  2008,  2039,  4586,  7052,  5062, 20793, 22058,\n",
       "            11,    86, 19763,  2039, 22079,  7982, 27064,  2076,  8672,  5062,\n",
       "            92, 10220,  2041,  4877,    17,  4708,    16, 29432,  2175, 14452,\n",
       "            87,  4092,  8398, 13077,    68,    79,  9971,    17,    87, 19131,\n",
       "         17640,    86, 18481,  2041, 23246,  5936,  7088,  5011,  5062,    85,\n",
       "         21349,  4868,  3619,     9,    17,  4064,     9, 13412, 11171, 17630,\n",
       "          3762, 24047, 12862, 30421, 27669,  2064,  3898,  4868,  3633,     9,\n",
       "            17,  3619,     9,  4868, 17640,    86, 18481,  2041,    18,     2]),\n",
       " 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'labels': tensor(1)}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RE_test_dataset[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b8929677-db16-480a-8bcc-03e2a6bcfb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "test_args = TrainingArguments(output_dir=\"./prediction\", do_train=False, do_predict=True, per_device_eval_batch_size=1, dataloader_drop_last=False)\n",
    "trainer = Trainer(model=model, args=test_args, compute_metrics=utils.compute_metrics, data_collator=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "be3f2006-74f9-4f86-8874-3e953bd8c7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 4846\n",
      "  Batch size = 1\n",
      "THCudaCheck FAIL file=../aten/src/THC/THCCachingHostAllocator.cpp line=280 error=710 : device-side assert triggered\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (710) : device-side assert triggered at ../aten/src/THC/THCCachingHostAllocator.cpp:280",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mRE_test_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m logits \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor(outputs\u001b[38;5;241m.\u001b[39mpredictions)\n\u001b[1;32m      3\u001b[0m prob \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39msoftmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer.py:2088\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2085\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   2087\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 2088\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2089\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPrediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\n\u001b[1;32m   2090\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2091\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   2092\u001b[0m output\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m   2093\u001b[0m     speed_metrics(\n\u001b[1;32m   2094\u001b[0m         metric_key_prefix,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2098\u001b[0m     )\n\u001b[1;32m   2099\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer.py:2178\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   2176\u001b[0m observed_num_examples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m   2177\u001b[0m \u001b[38;5;66;03m# Main evaluation loop\u001b[39;00m\n\u001b[0;32m-> 2178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dataloader):\n\u001b[1;32m   2179\u001b[0m     \u001b[38;5;66;03m# Update the observed num examples\u001b[39;00m\n\u001b[1;32m   2180\u001b[0m     observed_batch_size \u001b[38;5;241m=\u001b[39m find_batch_size(inputs)\n\u001b[1;32m   2181\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m observed_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:521\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    520\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 521\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    524\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    525\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:563\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    561\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_fetcher\u001b[38;5;241m.\u001b[39mfetch(index)  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m--> 563\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpin_memory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpin_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py:54\u001b[0m, in \u001b[0;36mpin_memory\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: pin_memory(sample) \u001b[38;5;28;01mfor\u001b[39;00m k, sample \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_fields\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# namedtuple\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\u001b[38;5;241m*\u001b[39m(pin_memory(sample) \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m data))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py:54\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, collections\u001b[38;5;241m.\u001b[39mabc\u001b[38;5;241m.\u001b[39mMapping):\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: \u001b[43mpin_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, sample \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(data, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_fields\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# namedtuple\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\u001b[38;5;241m*\u001b[39m(pin_memory(sample) \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m data))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/utils/data/_utils/pin_memory.py:50\u001b[0m, in \u001b[0;36mpin_memory\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpin_memory\u001b[39m(data):\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m---> 50\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpin_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, string_classes):\n\u001b[1;32m     52\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (710) : device-side assert triggered at ../aten/src/THC/THCCachingHostAllocator.cpp:280"
     ]
    }
   ],
   "source": [
    "outputs = trainer.predict(RE_test_dataset)\n",
    "logits = torch.FloatTensor(outputs.predictions)\n",
    "prob = F.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "result = torch.argmax(logits, axis=-1).detach().cpu().numpy()\n",
    "\n",
    "pred_answer = result.tolist()\n",
    "pred_answer = utils.num_to_label(pred_answer)\n",
    "output_prob = prob.tolist()\n",
    "\n",
    "output = pd.read_csv(\"./dataset/finance_data.csv\")\n",
    "output[\"pred_label\"] = pred_answer\n",
    "output[\"probs\"] = output_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4684099f-db58-4ed8-b6e9-aa80f0e77400",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 실행 시간을 기록합니다.\n",
    "now = datetime.now()\n",
    "inference_start_time = now.strftime(\"%d-%H-%M\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Test 점수 확인\n",
    "predict_dev = True  # dev set에 대한 prediction 결과값 구하기 (output분석)\n",
    "predict_submit = False  # dev set은 evaluation만 하고 submit할 결과값 구하기\n",
    "if predict_dev:\n",
    "    \n",
    "\n",
    "    output.to_csv(os.path.join(path, f\"dev_submission_{inference_start_time}.csv\"), index=False)\n",
    "    output.to_csv(f\"./prediction/dev_submission_{inference_start_time}.csv\", index=False)  # 최종적으로 완성된 예측한 라벨 csv 파일 형태로 저장.\n",
    "if predict_submit:\n",
    "    metrics = trainer.evaluate(RE_test_dataset)\n",
    "    print(\"Training is complete!\")\n",
    "    print(\"==================== Test metric score ====================\")\n",
    "    print(\"eval loss: \", metrics[\"eval_loss\"])\n",
    "    print(\"eval auprc: \", metrics[\"eval_auprc\"])\n",
    "    print(\"eval micro f1 score: \", metrics[\"eval_micro f1 score\"])\n",
    "\n",
    "    outputs = trainer.predict(RE_predict_dataset)\n",
    "    logits = torch.FloatTensor(outputs.predictions)\n",
    "    prob = F.softmax(logits, dim=-1).detach().cpu().numpy()\n",
    "    result = torch.argmax(logits, axis=-1).detach().cpu().numpy()\n",
    "\n",
    "    pred_answer = result.tolist()\n",
    "    pred_answer = utils.num_to_label(pred_answer)\n",
    "    output_prob = prob.tolist()\n",
    "\n",
    "    output = pd.read_csv(\"./prediction/sample_submission.csv\")\n",
    "    output[\"pred_label\"] = pred_answer\n",
    "    output[\"probs\"] = output_prob\n",
    "\n",
    "    output.to_csv(os.path.join(path, f\"submission_{inference_start_time}.csv\"), index=False)\n",
    "    output.to_csv(f\"./prediction/submission_{inference_start_time}.csv\", index=False)  # 최종적으로 완성된 예측한 라벨 csv 파일 형태로 저장.\n",
    "#### 필수!! ##############################################\n",
    "print(\"==================== Inference finish! ====================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed42560f-1525-4710-829c-898e65f5a1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
